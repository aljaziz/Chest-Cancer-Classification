{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Turja\\\\MLOps\\\\Chest-Cancer-Classification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    training_data: Path\n",
    "    validation_data: Path\n",
    "    all_image_path: list\n",
    "    params_epochs: int\n",
    "    params_weights: str\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_classes: int\n",
    "    params_device: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChestCancerClassification.constants import *\n",
    "from ChestCancerClassification.utils.utils import read_yaml, create_directories\n",
    "import torch\n",
    "import torchvision\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        params = self.params\n",
    "        training_data = os.path.join(\n",
    "            self.config.data_ingestion.unzip_dir, \"Chest_CT_Scan_Data/train\"\n",
    "        )\n",
    "        validation_data = os.path.join(\n",
    "            self.config.data_ingestion.unzip_dir, \"Chest_CT_Scan_Data/valid\"\n",
    "        )\n",
    "        all_image_path = glob(f\"artifacts/data_ingestion/Chest_CT_Scan_Data/*/*/*.png\")\n",
    "        create_directories([Path(training.root_dir)])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            validation_data=Path(validation_data),\n",
    "            all_image_path=all_image_path,\n",
    "            params_weights=params.WEIGHTS,\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            params_learning_rate=params.LEARNING_RATE,\n",
    "            params_classes=params.CLASSES,\n",
    "            params_device=params.DEVICE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        model = models.densenet121(weights=self.config.params_weights)\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = torch.nn.Linear(num_ftrs, self.config.params_classes)\n",
    "        self.model = model.to(self.config.params_device)\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.config.params_learning_rate\n",
    "        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.config.params_device)\n",
    "\n",
    "    def _compute_img_mean_std(self, image_paths):\n",
    "        \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "        \"\"\"\n",
    "\n",
    "        img_h, img_w = self.config.params_image_size, self.config.params_image_size\n",
    "        imgs = []\n",
    "        means, stdevs = [], []\n",
    "\n",
    "        for i in range(len(image_paths)):\n",
    "            img = cv2.imread(image_paths[i])\n",
    "            img = cv2.resize(img, (img_h, img_w))\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.stack(imgs, axis=3)\n",
    "        print(imgs.shape)\n",
    "\n",
    "        imgs = imgs.astype(np.float32) / 255.0\n",
    "\n",
    "        for i in range(3):\n",
    "            pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "            means.append(np.mean(pixels))\n",
    "            stdevs.append(np.std(pixels))\n",
    "\n",
    "        means.reverse()  # BGR --> RGB\n",
    "        stdevs.reverse()\n",
    "\n",
    "        print(\"normMean = {}\".format(means))\n",
    "        print(\"normStd = {}\".format(stdevs))\n",
    "        return means, stdevs\n",
    "\n",
    "    def _prepare_transforms(self):\n",
    "        norm_mean, norm_std = self._compute_img_mean_std(self.config.all_image_path)\n",
    "        train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    (self.config.params_image_size, self.config.params_image_size)\n",
    "                ),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(20),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(norm_mean, norm_std),\n",
    "            ]\n",
    "        )\n",
    "        test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(\n",
    "                    (self.config.params_image_size, self.config.params_image_size)\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(norm_mean, norm_std),\n",
    "            ]\n",
    "        )\n",
    "        return train_transforms, test_transforms\n",
    "\n",
    "    def train_valid_dataloader(self):\n",
    "        train_transforms, valid_transforms = self._prepare_transforms()\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            self.config.training_data, transform=train_transforms\n",
    "        )\n",
    "        valid_dataset = datasets.ImageFolder(\n",
    "            self.config.validation_data, transform=valid_transforms\n",
    "        )\n",
    "        self.train_dataloader = DataLoader(\n",
    "            train_dataset, batch_size=self.config.params_batch_size, shuffle=True\n",
    "        )\n",
    "        self.val_dataloader = DataLoader(\n",
    "            valid_dataset, batch_size=self.config.params_batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model):\n",
    "        torch.save(model, path)\n",
    "\n",
    "    def _train(self, epoch):\n",
    "        total_loss_train, total_acc_train = [], []\n",
    "        self.model.train()\n",
    "        train_loss = AverageMeter()\n",
    "        train_acc = AverageMeter()\n",
    "        curr_iter = (self.config.params_epochs - 1) * len(self.train_dataloader)\n",
    "        for i, data in enumerate(self.train_dataloader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "            images = Variable(images).to(self.config.params_device)\n",
    "            labels = Variable(labels).to(self.config.params_device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "            train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item() / N)\n",
    "            train_loss.update(loss.item())\n",
    "            curr_iter += 1\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print(\n",
    "            \"[epoch %d], [train loss %.5f], [train acc %.5f]\"\n",
    "            % (epoch, train_loss.avg, train_acc.avg)\n",
    "        )\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        total_loss_train.append(train_loss.avg)\n",
    "        total_acc_train.append(train_acc.avg)\n",
    "        return train_loss.avg, train_acc.avg\n",
    "\n",
    "    def _validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        val_loss = AverageMeter()\n",
    "        val_acc = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(self.val_dataloader):\n",
    "                images, labels = data\n",
    "                N = images.size(0)\n",
    "                images = Variable(images).to(self.config.params_device)\n",
    "                labels = Variable(labels).to(self.config.params_device)\n",
    "                outputs = self.model(images)\n",
    "                prediction = outputs.max(1, keepdim=True)[1]\n",
    "                val_acc.update(\n",
    "                    prediction.eq(labels.view_as(prediction)).sum().item() / N\n",
    "                )\n",
    "                val_loss.update(self.criterion(outputs, labels).item())\n",
    "\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print(\n",
    "            \"[epoch %d], [val loss %.5f], [val acc %.5f]\"\n",
    "            % (epoch, val_loss.avg, val_acc.avg)\n",
    "        )\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        return val_loss.avg, val_acc.avg\n",
    "\n",
    "    def fit(self):\n",
    "        total_loss_val, total_acc_val = [], []\n",
    "        best_val_acc = 0\n",
    "        for epoch in tqdm(range(self.config.params_epochs)):\n",
    "            loss_train, acc_train = self._train(epoch)\n",
    "            loss_val, acc_val = self._validate(epoch)\n",
    "            total_loss_val.append(loss_val)\n",
    "            total_acc_val.append(acc_val)\n",
    "            if acc_val > best_val_acc:\n",
    "                best_val_acc = acc_val\n",
    "                print(\"*****************************************************\")\n",
    "                print(\n",
    "                    \"best record: [epoch %d], [val loss %.5f], [val acc %.5f]\"\n",
    "                    % (epoch, loss_val, acc_val)\n",
    "                )\n",
    "                print(\"*****************************************************\")\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model={\n",
    "                \"epoch\": self.config.params_epochs,\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"loss_fn\": self.criterion,\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-07 22:04:43,718: INFO: utils: yaml file: config\\config.yaml lodded successfully]\n",
      "[2024-03-07 22:04:43,727: INFO: utils: yaml file: params.yaml lodded successfully]\n",
      "[2024-03-07 22:04:43,728: INFO: utils: created directory at: artifacts]\n",
      "[2024-03-07 22:04:43,735: INFO: utils: created directory at: artifacts\\training]\n",
      "(224, 224, 3, 988)\n",
      "normMean = [0.29797444, 0.29795608, 0.29797533]\n",
      "normStd = [0.2599838, 0.25996947, 0.25998133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 0], [train loss 1.72421], [train acc 0.38844]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:19,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 0], [val loss 175496.04688], [val acc 0.40625]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 0], [val loss 175496.04688], [val acc 0.40625]\n",
      "*****************************************************\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [train loss 1.26057], [train acc 0.49437]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:17<01:09,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 89.52129], [val acc 0.20833]\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [train loss 1.07682], [train acc 0.52375]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:26<01:00,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 4.35809], [val acc 0.25000]\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [train loss 1.00966], [train acc 0.55250]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:34<00:51,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.05225], [val acc 0.47917]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 3], [val loss 1.05225], [val acc 0.47917]\n",
      "*****************************************************\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [train loss 1.01584], [train acc 0.51594]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:43<00:43,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.12303], [val acc 0.55208]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 4], [val loss 1.12303], [val acc 0.55208]\n",
      "*****************************************************\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [train loss 0.91112], [train acc 0.56906]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:52<00:34,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.13483], [val acc 0.37500]\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [train loss 1.12252], [train acc 0.52500]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:00<00:25,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 4.95026], [val acc 0.50000]\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [train loss 1.15398], [train acc 0.49750]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:09<00:17,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 19.46103], [val acc 0.43750]\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [train loss 0.98887], [train acc 0.55812]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:17<00:08,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 1.37365], [val acc 0.37500]\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [train loss 1.02676], [train acc 0.55031]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:26<00:00,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 1.14872], [val acc 0.61458]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 9], [val loss 1.14872], [val acc 0.61458]\n",
      "*****************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_dataloader()\n",
    "    training.fit()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancerEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
